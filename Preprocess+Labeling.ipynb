{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import itertools\n",
    "import re\n",
    "import csv\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# 텍스트에 포함되어 있는 특수 문자 및 중복 띄어쓰기 제거\n",
    "def preprocessing(readData):\n",
    "    text = re.sub('[×%[\\'(-=.#/?:$}]', '', readData)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text\n",
    "stop_words = set(stopwords.words('english'))  # 불용어 제거\n",
    "\n",
    "corpus_root = \"C:/Users/sua91/nltk_data/Genomics-Informatics-Corpus-master/GNI Corpus 1.0/sentence_tokenized\"\n",
    "\n",
    "# 전처리할 데이터 제목 리스트를 gni_list에 저장\n",
    "f=open(\"gni_list.txt\",\"r\",encoding = 'utf8')\n",
    "g_lines=f.readlines()\n",
    "gni_list=[]\n",
    "for x in g_lines:\n",
    "    gni_list.append(x[:-1])\n",
    "f.close()\n",
    "\n",
    "# 전처리한 최종 data를 저장하는 리스트(csv파일에 포함될 text)\n",
    "final_data_list = []\n",
    "\n",
    "### 메인 코드 ###\n",
    "# sentence_tokenized 내에 존재하는 모든 코퍼스에 대해 진행\n",
    "for text in gni_list:\n",
    "    gniCorpus = nltk.corpus.PlaintextCorpusReader(corpus_root, text, encoding=\"utf-8\")  \n",
    "    gniSents = gniCorpus.sents()   # text 토큰화\n",
    "    gniSents= list(itertools.chain.from_iterable(gniSents))  # 이중 리스트를 1차원 리스트로 변환\n",
    "    result = []\n",
    "    # 불용어 제거\n",
    "    for w in gniSents:\n",
    "        if w not in stop_words:\n",
    "            result.append(w)\n",
    "    '''\n",
    "    # 명사만 따로 분류(코드에서는 활용하지 않았음.)\n",
    "    tagged = nltk.pos_tag(result)\n",
    "    result = [word for word, pos in tagged if pos in ['NN', 'NNP']]  # 명사추출\n",
    "    '''\n",
    "    result = \" \".join(result)   # 리스트를 문자열로 변환\n",
    "    result = preprocessing(result)  # 특수문자, 중복 띄어쓰기 제거\n",
    "\n",
    "    \n",
    "    # 특수 용어 리스트 구축\n",
    "    f=open(\"gene_with_protein_product_name.txt\",\"r\",encoding = 'utf8')\n",
    "    p_lines=f.readlines()\n",
    "    protein=[]\n",
    "    for x in p_lines:\n",
    "        protein.append(x[:-1])  # \\n 기호 제거\n",
    "    f.close()\n",
    "\n",
    "    f=open(\"non-coding_RNA_name.txt\",\"r\",encoding = 'utf8')\n",
    "    r_lines=f.readlines()\n",
    "    RNA=[]\n",
    "    for x in r_lines:\n",
    "        RNA.append(x[:-1])\n",
    "    f.close()\n",
    "\n",
    "    f=open(\"pseudogene_name.txt\",\"r\",encoding = 'utf8')\n",
    "    ps_lines=f.readlines()\n",
    "    pseudogene=[]\n",
    "    for x in ps_lines:\n",
    "        pseudogene.append(x[:-1])\n",
    "    f.close()\n",
    "    \n",
    "    num = []\n",
    "    num_pro = 0\n",
    "    num_rna = 0\n",
    "    num_sequence = 0\n",
    "\n",
    "    for i in protein:\n",
    "        if i in result:\n",
    "            num_pro += 1\n",
    "        \n",
    "    for i in RNA:\n",
    "        if i in result:\n",
    "            num_rna += 1\n",
    "        \n",
    "    for i in pseudogene:\n",
    "        if i in result:\n",
    "            num_sequence += 1\n",
    "        \n",
    "    sequence = re.findall(r'\\b[ACGT]{2,}\\b', result)\n",
    "    num_sequence += len(sequence)\n",
    "\n",
    "    if num_pro == 0 and num_rna == 0 and num_sequence == 0:\n",
    "        type = 'etc'\n",
    "\n",
    "    num = [num_pro, num_rna, num_sequence]\n",
    "    if num.index(max(num)) == 0:\n",
    "        type = 'protein'\n",
    "    elif num.index(max(num)) == 1:\n",
    "        type = 'RNA'\n",
    "    else:\n",
    "        type = 'sequence'\n",
    "    \n",
    "    final_data_list += [[result, type]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(final_data_list)\n",
    "df.to_csv(\"dataset.csv\", header = ['text', 'type'], index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
